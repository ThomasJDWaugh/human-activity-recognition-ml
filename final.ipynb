{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.70      0.28      0.40       174\n",
      "     Jogging       0.96      0.98      0.97       689\n",
      "     Sitting       0.69      1.00      0.81        22\n",
      "    Standing       1.00      0.74      0.85        43\n",
      "    Upstairs       0.82      0.34      0.49       238\n",
      "     Walking       0.76      0.99      0.86       768\n",
      "\n",
      "    accuracy                           0.84      1934\n",
      "   macro avg       0.82      0.72      0.73      1934\n",
      "weighted avg       0.84      0.84      0.81      1934\n",
      "\n",
      "  user_snippet predicted_activity\n",
      "0       8054_0            Walking\n",
      "1       8054_1            Sitting\n",
      "2       8054_2            Walking\n",
      "3       8054_3           Standing\n",
      "4       8054_4            Walking\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load datasets\n",
    "metadata = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata.csv\")\n",
    "signals = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals.csv\")\n",
    "metadata_test = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata_test.csv\")\n",
    "signals_test = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals_test.csv\")\n",
    "metadata_kaggle = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata_kaggle.csv\")\n",
    "signals_kaggle = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals_kaggle.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "def create_features(df):\n",
    "    grouped = df.groupby(\"user_snippet\")\n",
    "    feature_df = grouped.agg({\n",
    "        \"x-axis\": ['mean', 'std', 'max', 'min', 'median', 'skew', 'sum'],\n",
    "        \"y-axis\": ['mean', 'std', 'max', 'min', 'median', 'skew', 'sum'],\n",
    "        \"z-axis\": ['mean', 'std', 'max', 'min', 'median', 'skew', 'sum'],\n",
    "        \"timestamp\": ['count']\n",
    "    })\n",
    "    feature_df.columns = ['_'.join(col).strip() for col in feature_df.columns.values]\n",
    "    feature_df.reset_index(inplace=True)\n",
    "\n",
    "    # Extra derived features\n",
    "    feature_df[\"mag_mean\"] = np.sqrt(\n",
    "        feature_df[\"x-axis_mean\"]**2 +\n",
    "        feature_df[\"y-axis_mean\"]**2 +\n",
    "        feature_df[\"z-axis_mean\"]**2\n",
    "    )\n",
    "    feature_df[\"total_energy\"] = np.sqrt(\n",
    "        feature_df[\"x-axis_sum\"]**2 +\n",
    "        feature_df[\"y-axis_sum\"]**2 +\n",
    "        feature_df[\"z-axis_sum\"]**2\n",
    "    )\n",
    "    feature_df[\"x_y_ratio\"] = feature_df[\"x-axis_mean\"] / (feature_df[\"y-axis_mean\"] + 1e-5)\n",
    "    feature_df[\"x_z_ratio\"] = feature_df[\"x-axis_mean\"] / (feature_df[\"z-axis_mean\"] + 1e-5)\n",
    "    feature_df[\"y_z_ratio\"] = feature_df[\"y-axis_mean\"] / (feature_df[\"z-axis_mean\"] + 1e-5)\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "# Create features for all datasets\n",
    "train_features = create_features(signals)\n",
    "val_features = create_features(signals_test)\n",
    "kaggle_features = create_features(signals_kaggle)\n",
    "\n",
    "# Merge with metadata\n",
    "train_df = metadata.merge(train_features, on=\"user_snippet\")\n",
    "val_df = metadata_test.merge(val_features, on=\"user_snippet\")\n",
    "kaggle_df = metadata_kaggle.merge(kaggle_features, on=\"user_snippet\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df[\"activity_encoded\"] = label_encoder.fit_transform(train_df[\"activity\"])\n",
    "val_df[\"activity_encoded\"] = label_encoder.transform(val_df[\"activity\"])\n",
    "\n",
    "# Select features and targets\n",
    "X_train = train_df.drop(columns=[\"user_snippet\", \"activity\", \"activity_encoded\"])\n",
    "y_train = train_df[\"activity_encoded\"]\n",
    "X_val = val_df.drop(columns=[\"user_snippet\", \"activity\", \"activity_encoded\"])\n",
    "y_val = val_df[\"activity_encoded\"]\n",
    "X_kaggle = kaggle_df.drop(columns=[\"user_snippet\"])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_kaggle_scaled = scaler.transform(X_kaggle)\n",
    "\n",
    "# Define base models\n",
    "rf = RandomForestClassifier(n_estimators=15, min_samples_split=2, min_samples_leaf=4,\n",
    "                            max_depth=5, max_features='log2', random_state=42)\n",
    "gbm = GradientBoostingClassifier(learning_rate=0.1, n_estimators=200, random_state=42)\n",
    "\n",
    "# Define the stacking ensemble\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('gbm', gbm)],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, penalty='l2', C=0.1),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = stacked_model.predict(X_val_scaled)\n",
    "print(classification_report(y_val, y_val_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Predict on Kaggle test set\n",
    "y_kaggle_pred = stacked_model.predict(X_kaggle_scaled)\n",
    "kaggle_labels = label_encoder.inverse_transform(y_kaggle_pred)\n",
    "\n",
    "# Create Kaggle output\n",
    "kaggle_output = metadata_kaggle[[\"user_snippet\"]].copy()\n",
    "kaggle_output[\"predicted_activity\"] = kaggle_labels\n",
    "kaggle_output.to_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/rf+gbm_2predictions.csv\", index=False)\n",
    "\n",
    "print(kaggle_output.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.8min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.9min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.9min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 2.9min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 2.9min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=3, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 8.8min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=3, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 8.8min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=3, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 8.8min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time= 9.7min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time= 9.7min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time= 9.7min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time=10.4min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time=15.2min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time=15.2min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=10; total time=20.6min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=10; total time=20.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=10; total time=20.8min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time=15.1min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 5.8min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 5.8min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 5.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 9.5min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 9.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 9.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 9.6min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 9.6min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=50; total time= 3.1min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=100; total time=14.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=100; total time=14.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=50; total time= 2.9min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=50; total time= 2.9min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=100; total time=14.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 6.0min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time=19.7min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time=19.6min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time=19.5min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time=12.0min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time=20.2min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time=12.0min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time=20.2min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=3, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time=20.1min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time=12.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 5.9min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 5.9min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=10; total time= 4.8min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=10; total time= 4.8min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=10; total time= 4.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=10; total time= 4.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=10; total time= 4.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=10; total time= 4.7min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time=11.9min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time=11.8min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 8.1min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time=11.8min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=10; total time= 4.9min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 8.1min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 8.3min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 3.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=10; total time= 4.9min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 3.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=10; total time= 4.9min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 3.0min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time= 2.9min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 6.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 6.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 6.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time= 2.9min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time= 2.9min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 4.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 4.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 4.8min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time=20.0min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time=19.9min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=1, rf__n_estimators=50; total time=19.9min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time=13.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time=13.9min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time= 5.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time=14.1min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time= 5.9min\n",
      "[CV] END final_estimator__C=0.1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time= 5.9min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 5.7min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 5.7min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 5.4min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=3, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time=11.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=200; total time=13.4min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=3, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time=11.2min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=3, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time=11.3min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=200; total time=13.2min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=5, gbm__n_estimators=300, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=200; total time=13.0min\n",
      "Validation Accuracy: 0.8107549120992761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.41      0.18      0.25       174\n",
      "     Jogging       0.94      0.98      0.96       689\n",
      "     Sitting       0.58      0.95      0.72        22\n",
      "    Standing       1.00      0.60      0.75        43\n",
      "    Upstairs       0.85      0.37      0.51       238\n",
      "     Walking       0.75      0.95      0.84       768\n",
      "\n",
      "    accuracy                           0.81      1934\n",
      "   macro avg       0.75      0.67      0.67      1934\n",
      "weighted avg       0.80      0.81      0.78      1934\n",
      "\n",
      "  user_snippet predicted_activity\n",
      "0       8054_0            Walking\n",
      "1       8054_1            Sitting\n",
      "2       8054_2            Walking\n",
      "3       8054_3           Standing\n",
      "4       8054_4            Walking\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import iqr, kurtosis, skew\n",
    "\n",
    "# Load datasets\n",
    "metadata = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata.csv\")\n",
    "signals = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals.csv\")\n",
    "metadata_test = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata_test.csv\")\n",
    "signals_test = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals_test.csv\")\n",
    "metadata_kaggle = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata_kaggle.csv\")\n",
    "signals_kaggle = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals_kaggle.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "def create_features(df):\n",
    "    grouped = df.groupby(\"user_snippet\")\n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "    for snippet, group in grouped:\n",
    "        row = {'user_snippet': snippet}\n",
    "        for axis in ['x-axis', 'y-axis', 'z-axis']:\n",
    "            values = group[axis].values\n",
    "            row[f'{axis}_mean'] = np.mean(values)\n",
    "            row[f'{axis}_std'] = np.std(values)\n",
    "            row[f'{axis}_max'] = np.max(values)\n",
    "            row[f'{axis}_min'] = np.min(values)\n",
    "            row[f'{axis}_median'] = np.median(values)\n",
    "            row[f'{axis}_iqr'] = iqr(values)\n",
    "            row[f'{axis}_kurtosis'] = kurtosis(values)\n",
    "            row[f'{axis}_skew'] = skew(values)\n",
    "            row[f'{axis}_sum'] = np.sum(values)\n",
    "            row[f'{axis}_range'] = np.ptp(values)\n",
    "        row[\"timestamp_count\"] = group[\"timestamp\"].count()\n",
    "\n",
    "        # Derived features\n",
    "        row[\"mag_mean\"] = np.sqrt(\n",
    "            row['x-axis_mean']**2 +\n",
    "            row['y-axis_mean']**2 +\n",
    "            row['z-axis_mean']**2\n",
    "        )\n",
    "        row[\"total_energy\"] = np.sqrt(\n",
    "            row['x-axis_sum']**2 +\n",
    "            row['y-axis_sum']**2 +\n",
    "            row['z-axis_sum']**2\n",
    "        )\n",
    "        row[\"x_y_ratio\"] = row['x-axis_mean'] / (row['y-axis_mean'] + 1e-5)\n",
    "        row[\"x_z_ratio\"] = row['x-axis_mean'] / (row['z-axis_mean'] + 1e-5)\n",
    "        row[\"y_z_ratio\"] = row['y-axis_mean'] / (row['z-axis_mean'] + 1e-5)\n",
    "\n",
    "        feature_df = pd.concat([feature_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "# Create features\n",
    "train_features = create_features(signals)\n",
    "val_features = create_features(signals_test)\n",
    "kaggle_features = create_features(signals_kaggle)\n",
    "\n",
    "# Merge with metadata\n",
    "train_df = metadata.merge(train_features, on=\"user_snippet\")\n",
    "val_df = metadata_test.merge(val_features, on=\"user_snippet\")\n",
    "kaggle_df = metadata_kaggle.merge(kaggle_features, on=\"user_snippet\")\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df[\"activity_encoded\"] = label_encoder.fit_transform(train_df[\"activity\"])\n",
    "val_df[\"activity_encoded\"] = label_encoder.transform(val_df[\"activity\"])\n",
    "\n",
    "# Split features and targets\n",
    "X_train = train_df.drop(columns=[\"user_snippet\", \"activity\", \"activity_encoded\"])\n",
    "y_train = train_df[\"activity_encoded\"]\n",
    "X_val = val_df.drop(columns=[\"user_snippet\", \"activity\", \"activity_encoded\"])\n",
    "y_val = val_df[\"activity_encoded\"]\n",
    "X_kaggle = kaggle_df.drop(columns=[\"user_snippet\"])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_kaggle_scaled = scaler.transform(X_kaggle)\n",
    "\n",
    "# Base models\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Meta-model\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Stacking classifier (without fitting yet)\n",
    "stack = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('gbm', gbm)],\n",
    "    final_estimator=meta_model,\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Parameter grid for tuning\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [10, 50, 100, 200],\n",
    "    'rf__max_depth': [3, 5, 10, None],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__max_features': ['sqrt', 'log2'],\n",
    "    'gbm__n_estimators': [100, 200, 300],\n",
    "    'gbm__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'gbm__max_depth': [3, 5, 7],\n",
    "    'final_estimator__C': [0.01, 0.1, 1, 10],\n",
    "    'final_estimator__penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    stack,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit search\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "best_model = random_search.best_estimator_\n",
    "y_val_pred = best_model.predict(X_val_scaled)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Predict on Kaggle\n",
    "y_kaggle_pred = best_model.predict(X_kaggle_scaled)\n",
    "kaggle_labels = label_encoder.inverse_transform(y_kaggle_pred)\n",
    "\n",
    "# Save submission\n",
    "submission = metadata_kaggle[[\"user_snippet\"]].copy()\n",
    "submission[\"predicted_activity\"] = kaggle_labels\n",
    "submission.to_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/rf+gbm_3_predictions.csv\", index=False)\n",
    "\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time= 2.1min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time= 2.1min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time= 2.1min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 4.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 4.6min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 4.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 4.6min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 4.6min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 4.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.7min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 4.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.3min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.3min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.3min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 4.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 4.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 2.0min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 8.2min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 8.1min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 2.0min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 8.1min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 2.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 2.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 2.0min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 6.2min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 6.2min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time=13.5min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time=13.6min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 2.0min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 6.2min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time=13.2min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time=13.2min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time=13.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time=13.1min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 2.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 2.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 1.9min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 6.1min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 6.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 5.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=100; total time= 5.1min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=100; total time= 5.2min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=100; total time= 5.0min\n",
      "Validation Accuracy: 0.8019648397104446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.40      0.16      0.23       174\n",
      "     Jogging       0.95      0.98      0.96       689\n",
      "     Sitting       0.66      0.95      0.78        22\n",
      "    Standing       1.00      0.70      0.82        43\n",
      "    Upstairs       0.81      0.25      0.38       238\n",
      "     Walking       0.72      0.96      0.83       768\n",
      "\n",
      "    accuracy                           0.80      1934\n",
      "   macro avg       0.76      0.67      0.67      1934\n",
      "weighted avg       0.79      0.80      0.77      1934\n",
      "\n",
      "Saved predictions to 'stacking_with_selection_kaggle_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import iqr, kurtosis, skew\n",
    "\n",
    "# Load data\n",
    "metadata = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata.csv\")\n",
    "signals = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals.csv\")\n",
    "metadata_test = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata_test.csv\")\n",
    "signals_test = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals_test.csv\")\n",
    "metadata_kaggle = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata_kaggle.csv\")\n",
    "signals_kaggle = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals_kaggle.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "def create_features(df):\n",
    "    grouped = df.groupby(\"user_snippet\")\n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "    for snippet, group in grouped:\n",
    "        row = {'user_snippet': snippet}\n",
    "        for axis in ['x-axis', 'y-axis', 'z-axis']:\n",
    "            values = group[axis].values\n",
    "            row[f'{axis}_mean'] = np.mean(values)\n",
    "            row[f'{axis}_std'] = np.std(values)\n",
    "            row[f'{axis}_max'] = np.max(values)\n",
    "            row[f'{axis}_min'] = np.min(values)\n",
    "            row[f'{axis}_median'] = np.median(values)\n",
    "            row[f'{axis}_iqr'] = iqr(values)\n",
    "            row[f'{axis}_kurtosis'] = kurtosis(values)\n",
    "            row[f'{axis}_skew'] = skew(values)\n",
    "            row[f'{axis}_sum'] = np.sum(values)\n",
    "            row[f'{axis}_range'] = np.ptp(values)\n",
    "        row[\"timestamp_count\"] = group[\"timestamp\"].count()\n",
    "\n",
    "        # Derived features\n",
    "        row[\"mag_mean\"] = np.sqrt(\n",
    "            row['x-axis_mean']**2 + row['y-axis_mean']**2 + row['z-axis_mean']**2\n",
    "        )\n",
    "        row[\"total_energy\"] = np.sqrt(\n",
    "            row['x-axis_sum']**2 + row['y-axis_sum']**2 + row['z-axis_sum']**2\n",
    "        )\n",
    "        row[\"x_y_ratio\"] = row['x-axis_mean'] / (row['y-axis_mean'] + 1e-5)\n",
    "        row[\"x_z_ratio\"] = row['x-axis_mean'] / (row['z-axis_mean'] + 1e-5)\n",
    "        row[\"y_z_ratio\"] = row['y-axis_mean'] / (row['z-axis_mean'] + 1e-5)\n",
    "\n",
    "        feature_df = pd.concat([feature_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "# Generate features\n",
    "train_features = create_features(signals)\n",
    "val_features = create_features(signals_test)\n",
    "kaggle_features = create_features(signals_kaggle)\n",
    "\n",
    "# Merge with metadata\n",
    "train_df = metadata.merge(train_features, on=\"user_snippet\")\n",
    "val_df = metadata_test.merge(val_features, on=\"user_snippet\")\n",
    "kaggle_df = metadata_kaggle.merge(kaggle_features, on=\"user_snippet\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df[\"activity_encoded\"] = label_encoder.fit_transform(train_df[\"activity\"])\n",
    "val_df[\"activity_encoded\"] = label_encoder.transform(val_df[\"activity\"])\n",
    "\n",
    "# Extract features and targets\n",
    "X_train = train_df.drop(columns=[\"user_snippet\", \"activity\", \"activity_encoded\"])\n",
    "y_train = train_df[\"activity_encoded\"]\n",
    "X_val = val_df.drop(columns=[\"user_snippet\", \"activity\", \"activity_encoded\"])\n",
    "y_val = val_df[\"activity_encoded\"]\n",
    "X_kaggle = kaggle_df.drop(columns=[\"user_snippet\"])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_full = scaler.fit_transform(X_train)\n",
    "X_val_scaled_full = scaler.transform(X_val)\n",
    "X_kaggle_scaled_full = scaler.transform(X_kaggle)\n",
    "\n",
    "# === FEATURE SELECTION ===\n",
    "rf_selector = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selector.fit(X_train_scaled_full, y_train)\n",
    "\n",
    "# Select top N features\n",
    "top_n = 40\n",
    "importances = rf_selector.feature_importances_\n",
    "indices = np.argsort(importances)[::-1][:top_n]\n",
    "selected_columns = X_train.columns[indices]\n",
    "\n",
    "# Reduce to selected features\n",
    "X_train_selected = X_train[selected_columns]\n",
    "X_val_selected = X_val[selected_columns]\n",
    "X_kaggle_selected = X_kaggle[selected_columns]\n",
    "\n",
    "# Re-scale selected features\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_val_scaled = scaler.transform(X_val_selected)\n",
    "X_kaggle_scaled = scaler.transform(X_kaggle_selected)\n",
    "\n",
    "# Base models\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Meta model\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Define stacking model\n",
    "stack = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('gbm', gbm)],\n",
    "    final_estimator=meta_model,\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Random search grid\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [5, 10, None],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__max_features': ['sqrt', 'log2'],\n",
    "    'gbm__n_estimators': [100, 200, 300],\n",
    "    'gbm__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'gbm__max_depth': [3, 5, 7],\n",
    "    'final_estimator__C': [0.01, 0.1, 1, 10],\n",
    "    'final_estimator__penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Run randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    stack,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=15,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "best_model = random_search.best_estimator_\n",
    "y_val_pred = best_model.predict(X_val_scaled)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Predict Kaggle\n",
    "y_kaggle_pred = best_model.predict(X_kaggle_scaled)\n",
    "kaggle_labels = label_encoder.inverse_transform(y_kaggle_pred)\n",
    "\n",
    "# Save results\n",
    "submission = metadata_kaggle[[\"user_snippet\"]].copy()\n",
    "submission[\"predicted_activity\"] = kaggle_labels\n",
    "submission.to_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/rf+gbm2_selected_features_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Saved predictions to 'stacking_with_selection_kaggle_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time= 1.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time= 1.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=200; total time= 1.6min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 3.4min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 3.4min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.4min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.4min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 3.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 3.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.0min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 4.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.1min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=2, rf__n_estimators=200; total time= 3.1min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 4.0min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 4.0min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 1.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 6.7min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 6.8min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 1.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=7, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=1, rf__n_estimators=100; total time= 6.1min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 1.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 1.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 1.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.8min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.8min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time=10.3min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time=10.3min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time= 1.5min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.1, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=5, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time= 4.8min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time=10.0min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time=10.1min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=log2, rf__min_samples_leaf=4, rf__n_estimators=100; total time=10.3min\n",
      "[CV] END final_estimator__C=10, final_estimator__penalty=l2, gbm__learning_rate=0.05, gbm__max_depth=7, gbm__n_estimators=300, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=4, rf__n_estimators=50; total time=10.1min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 1.6min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 1.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=100, rf__max_depth=5, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 1.5min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 4.6min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 4.6min\n",
      "[CV] END final_estimator__C=1, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=5, gbm__n_estimators=200, rf__max_depth=None, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=50; total time= 4.4min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=100; total time= 3.9min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=100; total time= 3.9min\n",
      "[CV] END final_estimator__C=0.01, final_estimator__penalty=l2, gbm__learning_rate=0.01, gbm__max_depth=3, gbm__n_estimators=300, rf__max_depth=10, rf__max_features=sqrt, rf__min_samples_leaf=2, rf__n_estimators=100; total time= 3.8min\n",
      "Validation Accuracy: 0.8076525336091003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.40      0.15      0.22       174\n",
      "     Jogging       0.94      0.98      0.96       689\n",
      "     Sitting       0.95      0.95      0.95        22\n",
      "    Standing       1.00      0.95      0.98        43\n",
      "    Upstairs       0.83      0.26      0.40       238\n",
      "     Walking       0.73      0.96      0.83       768\n",
      "\n",
      "    accuracy                           0.81      1934\n",
      "   macro avg       0.81      0.71      0.72      1934\n",
      "weighted avg       0.80      0.81      0.77      1934\n",
      "\n",
      "Saved predictions to 'stacking_with_selection_kaggle_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import iqr, kurtosis, skew\n",
    "\n",
    "# Load data\n",
    "metadata = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata.csv\")\n",
    "signals = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals.csv\")\n",
    "metadata_test = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata_test.csv\")\n",
    "signals_test = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals_test.csv\")\n",
    "metadata_kaggle = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/metadata_kaggle.csv\")\n",
    "signals_kaggle = pd.read_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/signals_kaggle.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "def create_features(df):\n",
    "    grouped = df.groupby(\"user_snippet\")\n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "    for snippet, group in grouped:\n",
    "        row = {'user_snippet': snippet}\n",
    "        for axis in ['x-axis', 'y-axis', 'z-axis']:\n",
    "            values = group[axis].values\n",
    "            row[f'{axis}_mean'] = np.mean(values)\n",
    "            row[f'{axis}_std'] = np.std(values)\n",
    "            row[f'{axis}_max'] = np.max(values)\n",
    "            row[f'{axis}_min'] = np.min(values)\n",
    "            row[f'{axis}_median'] = np.median(values)\n",
    "            row[f'{axis}_iqr'] = iqr(values)\n",
    "            row[f'{axis}_kurtosis'] = kurtosis(values)\n",
    "            row[f'{axis}_skew'] = skew(values)\n",
    "            row[f'{axis}_sum'] = np.sum(values)\n",
    "            row[f'{axis}_range'] = np.ptp(values)\n",
    "        row[\"timestamp_count\"] = group[\"timestamp\"].count()\n",
    "\n",
    "        # Derived features\n",
    "        row[\"mag_mean\"] = np.sqrt(\n",
    "            row['x-axis_mean']**2 + row['y-axis_mean']**2 + row['z-axis_mean']**2\n",
    "        )\n",
    "        row[\"total_energy\"] = np.sqrt(\n",
    "            row['x-axis_sum']**2 + row['y-axis_sum']**2 + row['z-axis_sum']**2\n",
    "        )\n",
    "        row[\"x_y_ratio\"] = row['x-axis_mean'] / (row['y-axis_mean'] + 1e-5)\n",
    "        row[\"x_z_ratio\"] = row['x-axis_mean'] / (row['z-axis_mean'] + 1e-5)\n",
    "        row[\"y_z_ratio\"] = row['y-axis_mean'] / (row['z-axis_mean'] + 1e-5)\n",
    "\n",
    "        feature_df = pd.concat([feature_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "# Generate features\n",
    "train_features = create_features(signals)\n",
    "val_features = create_features(signals_test)\n",
    "kaggle_features = create_features(signals_kaggle)\n",
    "\n",
    "# Merge with metadata\n",
    "train_df = metadata.merge(train_features, on=\"user_snippet\")\n",
    "val_df = metadata_test.merge(val_features, on=\"user_snippet\")\n",
    "kaggle_df = metadata_kaggle.merge(kaggle_features, on=\"user_snippet\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df[\"activity_encoded\"] = label_encoder.fit_transform(train_df[\"activity\"])\n",
    "val_df[\"activity_encoded\"] = label_encoder.transform(val_df[\"activity\"])\n",
    "\n",
    "# Extract features and targets\n",
    "X_train = train_df.drop(columns=[\"user_snippet\", \"activity\", \"activity_encoded\"])\n",
    "y_train = train_df[\"activity_encoded\"]\n",
    "X_val = val_df.drop(columns=[\"user_snippet\", \"activity\", \"activity_encoded\"])\n",
    "y_val = val_df[\"activity_encoded\"]\n",
    "X_kaggle = kaggle_df.drop(columns=[\"user_snippet\"])\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_full = scaler.fit_transform(X_train)\n",
    "X_val_scaled_full = scaler.transform(X_val)\n",
    "X_kaggle_scaled_full = scaler.transform(X_kaggle)\n",
    "\n",
    "# === FEATURE SELECTION ===\n",
    "rf_selector = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selector.fit(X_train_scaled_full, y_train)\n",
    "\n",
    "# Select top N features\n",
    "top_n = 30\n",
    "importances = rf_selector.feature_importances_\n",
    "indices = np.argsort(importances)[::-1][:top_n]\n",
    "selected_columns = X_train.columns[indices]\n",
    "\n",
    "# Reduce to selected features\n",
    "X_train_selected = X_train[selected_columns]\n",
    "X_val_selected = X_val[selected_columns]\n",
    "X_kaggle_selected = X_kaggle[selected_columns]\n",
    "\n",
    "# Re-scale selected features\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_val_scaled = scaler.transform(X_val_selected)\n",
    "X_kaggle_scaled = scaler.transform(X_kaggle_selected)\n",
    "\n",
    "# Base models\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Meta model\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Define stacking model\n",
    "stack = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('gbm', gbm)],\n",
    "    final_estimator=meta_model,\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Random search grid\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [5, 10, None],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__max_features': ['sqrt', 'log2'],\n",
    "    'gbm__n_estimators': [100, 200, 300],\n",
    "    'gbm__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'gbm__max_depth': [3, 5, 7],\n",
    "    'final_estimator__C': [0.01, 0.1, 1, 10],\n",
    "    'final_estimator__penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Run randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    stack,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=15,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "best_model = random_search.best_estimator_\n",
    "y_val_pred = best_model.predict(X_val_scaled)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(classification_report(y_val, y_val_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Predict Kaggle\n",
    "y_kaggle_pred = best_model.predict(X_kaggle_scaled)\n",
    "kaggle_labels = label_encoder.inverse_transform(y_kaggle_pred)\n",
    "\n",
    "# Save results\n",
    "submission = metadata_kaggle[[\"user_snippet\"]].copy()\n",
    "submission[\"predicted_activity\"] = kaggle_labels\n",
    "submission.to_csv(\"/Users/dawidnawrocki/Documents/Machine Learning/7021datsci-challenge-2025/rf+gbm3_selected_features_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Saved predictions to 'stacking_with_selection_kaggle_predictions.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
